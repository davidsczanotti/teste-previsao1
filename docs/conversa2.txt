# tactiq.io free youtube transcript
# No title found
# https://www.youtube.com/watch/HjScAwMelXQ

00:00:00.000 can we train convolutional neural networks  or CNNs for short to predict stocks?
00:00:05.340 my name is Jin Choi and in this video  we're going to find that out [Music]
00:00:12.540 CNNs are famous for their application in image  recognition let me explain how they work using an
00:00:18.540 example this is a picture of my dog Cinder to tell  whether this picture contains a dog a CNN will
00:00:24.960 focus on a section of the image at a time it'll  then use something called 'filters' to detect
00:00:30.120 patterns in each section one filter for example  may look for dog legs and since this section does
00:00:36.480 contain legs the score generated by this filter  will be high another filter may look for a dog
00:00:42.420 nose this section doesn't contain a nose so it'll  score low the CNN will then move on to the next
00:00:48.660 section and apply the filters all over again it'll  do this for all sections of the image and then
00:00:54.720 use the scores to determine whether the image  contains a dog now you might wonder how a CNN
00:00:59.700 would know to look for dog legs and noses because  we don't manually tell the model what to look for
00:01:05.580 so why wouldn't it look for something random like  wings that's the power of CNNs it automatically
00:01:12.420 learns filters that are useful for detecting  dogs if you train a CNN to identify birds it
00:01:18.360 would automatically learn to look for wings we can  harness this power of CNNs to try to predict stock
00:01:23.640 prices if stocks tend to go up after displaying  certain patterns CNN should be able to detect
00:01:29.160 what those patterns are after all some traders do  exactly this they study price charts to see where
00:01:35.700 stuff will go next now I'm not the only one who  used CNNs to predict stocks but I am going to do
00:01:41.640 it a little differently than many because CNNs are  used so much for images people automatically look
00:01:47.820 to use images to predict stocks as well they'll  literally save images of stock charts and use
00:01:53.340 them as inputs those images are two-dimensional  data that require two-dimensional CNNs but we
00:01:59.520 don't have to use images historical prices are  actually one-dimensional data so we can use
00:02:05.160 one-dimensional CNNs instead with one-dimensional  CNNs we would create sections of the data along
00:02:10.979 just one axis and apply one-dimensional filters  to each section now don't get me wrong I'm not
00:02:16.980 knocking those who use two-dimensional CNNs  some people I really respect have done that
00:02:22.140 but I've chosen to use a one-dimensional CNNs  because it's simpler and because it's sufficient
00:02:28.980 let's now go through the code if you're not a  programmer and want to skip the gory details
00:02:35.640 feel free to go to the next chapter the code I'll  go through is available on GitHub and the link to
00:02:41.460 it is in the video description I'm not going to go  through every line of this code because some of it
00:02:46.980 is boilerplate instead I'm going to concentrate  on the more meaningful sections of the code and
00:02:53.400 emphasize their data science aspects the execution  of the code begins at main.py the first two lines
00:02:59.460 of the code downloads the daily price history of  SPY which is a fund that tracks the 500 largest
00:03:05.220 U.S stocks we only take the closing price of  each trading day because they're what investors
00:03:09.960 normally care about the most I may explain why  they care more about closing prices than say
00:03:14.760 opening prices in a short video later so make  sure to subscribe the next slide processes the
00:03:20.700 data into a format CNNs can consume I won't walk  through the process inputs method line by line
00:03:26.280 but let me explain what it does here's what the  data looks looks like if our window length is
00:03:30.960 10 we take values from the second column to the  11th column so that we have 10 values and then
00:03:36.780 we divide these numbers by the value in the First  Column so that the inputs are not influenced by
00:03:42.180 their starting level this step is very important  if we don't scale the data it would be like asking
00:03:48.420 our CNN to tailor a suit that fits both a 10  foot Giant and a three foot child the CNN will
00:03:55.200 fail finally we subtract all values by one and  that gets us our first row of inputs this input
00:04:01.500 represents cumulative gains of the stock since the  January 29 1993. to construct the second row of
00:04:07.980 inputs we take value from the third column to the  12th column and apply all the same steps that we
00:04:14.040 talked about the second row consists of cumulative  gains of stocks since February 1st 1993. we keep
00:04:21.420 iterating to get more rows until we can't anymore  when we finish running the process inputs method
00:04:26.940 the 'x_df' variable looks like this the index  shows the reference state which is the date of
00:04:32.940 the most recent input T-9 shows a cumulative gains  9 days before the reference date T-0 shows the
00:04:39.540 cumulative games as of the reference state so next  line prepares the target data which is the data we
00:04:45.660 want CNNs to predict I've set this as a percent  change in the stock's price from one day after
00:04:50.640 the reference day to two days after the reference  date for example if the reference date of February
00:04:56.160 16th then the target is the price change from the  17th to the 18th notice I didn't choose a target
00:05:02.520 to be the price change from the 16th to the 17th  that's because after we collect the closing price
00:05:08.340 data on the 16th it's too late to buy stocks  on the 16th after running the process targets
00:05:14.640 method the 'y_series' variable looks like this  note that the index refers to the reference date
00:05:20.220 not the day when the price changes occurred this  is to keep the y_series index match x_df's index
00:05:27.120 the next two lines of code make sure we only  keep data rows where we have full complements of
00:05:32.280 inputs and target the next code block involving  the 'for' loop trains and tests the model on a
00:05:37.560 walk forward basis starting in the year 2010 we  take all data before the year after training data
00:05:43.380 and then see how the model performs during that  year in other words in 2010. during the next 'for'
00:05:49.320 loop iteration we moved the year to 2011 so we  train the model using data up until the beginning
00:05:54.720 of that year and test the model during 2011. we  keep doing this until our current year the walk
00:06:01.560 forward method simulates how we would have used  the model to trade and it's as if we retrain the
00:06:07.500 model at the beginning of each year and use the  newly trained model to trade during the rest of
00:06:12.360 the year the first six lines of the loop buckets  the training and test data sets and then we train
00:06:18.960 the model let's step into the train method you'll  notice that I've chosen to use PyTorch library
00:06:24.600 which is the industry standard nowadays the first  six lines of this code tells PyTorch to store
00:06:30.480 data in the GPU if possible because it would run  faster than in the CPU the next line converts
00:06:37.440 the data into PyTorch's format we then create a  data folder which allows us to train on batches
00:06:42.780 of 64 data rows at a time training on batches is  faster than training on the whole data set each
00:06:48.000 time and it also gives us some data science  benefits that I won't get into by the way if
00:06:53.220 you want me to elaborate on anything feel free to  ask in the comments the next slide defines a loss
00:06:59.160 function we're going to use the most popular  loss function is the MSE loss, which penalizes
00:07:04.560 models by the squared of the difference between  predicted and actual numbers MSE works great if
00:07:10.560 the target data has a Gaussian distribution where  extreme values are rare unfortunately our
00:07:16.440 Target data contains some more extreme negative  values as compared to the gaussian so we use the
00:07:22.140 Huber loss function instead to blunt the impact of  these extreme values after that we instantiate the
00:07:28.680 CNN model you can find the model definition in  the CNNStocksModule class under model.py the
00:07:35.460 first component of the model is a one-dimensional  convolution layer the first argument of this layer
00:07:40.980 hard coded as 1 indicates the number of features in  our case we're only using one feature based on
00:07:47.640 closing stock prices if we were to use another  feature as well like one based on opening prices
00:07:52.860 then would increase this number the number of  output channels indicate the number of filters to
00:07:59.040 use you basically ask yourself how many patterns  do you want a CNN to look for I've chosen to
00:08:04.800 look for 30 patterns the kernel size determines  the size of each filter recall that I'm using a
00:08:10.860 window length of 10 so if the kernel size is 8 we  apply filters on values from the first to eighth
00:08:17.220 element and then from second to ninth element  and finally from third to Tenth element so in
00:08:23.220 that case we get three scores for each filter  I have chosen to use a kernel size of 10 which
00:08:28.620 means that the filter covers the entire row of  data so you only get one score per row the
00:08:34.559 num_scores variable tracks this number of scores per  row the max pool layer takes the maximum score
00:08:40.380 of each row for each filter we make the model ask  whether the filter detected the pattern anywhere
00:08:45.720 in the row in the case where the kernel size is  smaller than the window length maybe the filter
00:08:50.940 detected a pattern earlier in the row but not  later on by taking the maximum score we only care
00:08:57.240 about the earlier incidence when the pattern did  manifest the final linear component combines the
00:09:02.880 scores from all filters to produce a stock price  prediction let's see how all of these components
00:09:07.920 work together in the forward method the first line  applies a CNN layer to our inputs the output's
00:09:13.740 first dimension denotes the row the second  dimension the filter and the third dimension the
00:09:19.320 score position the second line of code applies the  max pool layer the output of this line gives us a
00:09:25.980 matrix where the First Dimension still denotes  the row and the second dimension denotes the
00:09:30.420 filter the third dimension always has size one  so we get rid of it using the squeeze method the
00:09:36.780 third line of code applies a Softmax function  across all filters for each row this scales the
00:09:42.540 score so that each filter score is relative to  other filter scores in other words even if a
00:09:48.600 filter had a high initial score it can obtain a  low value after Softmax of other filters scored
00:09:54.420 even higher this was useful because we only care  about the best matching filters finally we apply
00:10:00.300 the linear component to combine these values into  a single prediction for each row of data let's
00:10:05.100 go back to the train method we've instantiated  the model so now we create the optimizer whose
00:10:11.280 job is to find the best set of parameters for the  model I chose to use the popular optimizer called
00:10:16.020 Adam with a standard learning rate the weight  decay helps fight against overfitting which is
00:10:20.940 the perennial problem in machine learning where  the model tries to memorize training data instead
00:10:25.920 of learning more general principles a little bit  of weight decay is good but too much can actually
00:10:30.480 harm the model so I've set it to a small number  the rest of the code consists of boilerplate to
00:10:35.880 train the model iteratively we go through the  entire data epochs number of times and I found
00:10:41.820 100 to be a big enough number for the number of  epochs and that's how we train our model let's go
00:10:47.760 back to main.py we just finished training in  the next line we use a trained model to make
00:10:54.000 predictions using the test templates I won't walk  through the predict method because it's pretty
00:10:58.920 straightforward and the rest of the code inside  the for loop shows how well the model performed
00:11:03.540 against the test outputs then coming out of the  'for' loop the code performs a very simple backtest
00:11:08.700 I won't go through the mechanics of the backtest because it's unrelated to model development
00:11:13.320 but simply put it invests in the stock if the  model predicts positive returns or holds cash
00:11:19.320 otherwise and that concludes our code walkthrough  [Music] let's see how well our model performs
00:11:28.500 running main.py produces the following outputs  R squared is a popular statistical metric that
00:11:34.380 shows how close the predictions were to actual  a perfect model score is one whereas a terrible
00:11:39.840 model scores zero or even negative unfortunately  the CNN model appears to be of the latter type
00:11:47.400 but there is a silver lining R squared is not the  end all and be all metric I won't explain why here
00:11:56.520 but some models with negative R squared are still  very useful in fact the correlations between model
00:12:03.060 predictions and actual tend to be positive when  we run a backtest we find that the model does
00:12:09.060 deliver a slightly better returns than the buy-and-hold strategy most of the time I say most
00:12:14.340 of the time because the results differ slightly every time you run the code also because the model
00:12:19.920 sometimes sits out of the market the risks of following the model is slightly lower as compared
00:12:26.400 to the buy-and-hold but overall the difference  between the model and buy-and-hold strategies are
00:12:31.320 not big enough to get us excited especially since we didn't factor in trading costs in our backtest
00:12:36.720 either are you disappointed that the strategy didn't work if you were, then it's time for a
00:12:41.460 reality check creating a market beating strategy is very hard and here is why the strategy I've
00:12:47.820 shown you in this video is simple it only took a few few hundred lines of code asset managers
00:12:54.120 have spent billions of dollars on creating new strategies I can almost guarantee you that they
00:13:00.600 experimented with models that are very similar to ours if the model had worked these asset managers
00:13:06.420 would have adopted it and that adoption may have stopped the strategy from working afterwards so if
00:13:12.360 you want a strategy that works you need something that's unique and that generally means something
00:13:17.160 that's more sophisticated now are there ways to improve the performance of this model
00:13:22.740 yes there are for one we can use data of many stocks and not just that of SPY doing this will
00:13:30.240 mitigate the effects of overfitting because we'll be using more data  another thing you can try is to
00:13:35.220 tune the hyper parameters  I've hard-coded several settings such as kernel size and a number of filters
00:13:40.740 we could use a library such as Optuna  to systematically find the best set of hyperparameters
00:13:47.100 lastly we can try more sophisticated  models Beyond using just a single layer of CNN
00:13:53.340 the possibilities are infinite although more  sophisticated models will struggle more with overfitting
00:13:59.340 if you want to see me tackle any  of these methods please leave a comment let me
00:14:05.340 finish this video with a plug about myself  I'm a financial advisor in Canada as you can see I
00:14:10.920 have a very deep data science background, which is very unusual for an advisor  I use my skills
00:14:16.140 to try to reach for better returns for my clients and to manage risks more intelligently  to clarify,
00:14:21.660 using data science doesn't mean day trading in and out of stocks frequently rather it means making
00:14:26.640 decisions that are based on data rather than gut feel if you'd like to learn more about how I use
00:14:31.920 data science to manage money feel free to visit our website which I posted in the description of
00:14:37.320 this video finally if you like to be alerted  when I apply new machine learning concepts in
00:14:41.760 finance make sure to subscribe to my channel  thank you for watching and see you next time [Music]
